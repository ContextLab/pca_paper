{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: davos in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (from davos) (65.6.3)\n",
      "Requirement already satisfied: packaging in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (from davos) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install davos\n",
    "import davos\n",
    "\n",
    "%conda install pytables\n",
    "\n",
    "davos.config.suppress_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "smuggle nltools as nlt            # pip: nltools==0.4.7\n",
    "\n",
    "smuggle nilearn as nl             # pip: nilearn==0.10.0\n",
    "smuggle nibabel as nib            # pip: nibabel==5.0.1\n",
    "\n",
    "smuggle datawrangler as dw        # pip: pydata-wrangler==0.2.2\n",
    "\n",
    "smuggle numpy as np               # pip: numpy==1.24.2\n",
    "smuggle matplotlib.pyplot as plt  # pip: matplotlib==3.7.0\n",
    "smuggle pandas as pd              # pip: pandas==1.5.3\n",
    "smuggle seaborn as sns            # pip: seaborn==0.12.2\n",
    "from skimage smuggle transform    # pip: scikit-image==0.20.0\n",
    "\n",
    "from sklearn.decomposition smuggle IncrementalPCA as PCA  # pip: scikit-learn==1.2.1\n",
    "from scipy.spatial.distance smuggle cdist                 # pip: scipy==1.10.1\n",
    "from scipy.io smuggle loadmat\n",
    "from tqdm smuggle tqdm            # pip: tqdm==4.64.1\n",
    "\n",
    "smuggle requests                  # pip: requests==2.28.2\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import warnings\n",
    "from glob import glob as lsdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "datadir = os.path.join(basedir, 'data')\n",
    "nii_dir = os.path.join(datadir, 'nii')\n",
    "\n",
    "zipfile_fname = os.path.join(nii_dir, 'Pieman2.zip')\n",
    "check_file = os.path.join(nii_dir, 'download_complete.txt')\n",
    "url = 'https://www.dropbox.com/s/7wiucuf4cprte6g/Pieman2.zip?dl=1'\n",
    "# url = 'https://www.dropbox.com/s/0g5nx37p64eubif/pieman_posterior_K700.mat?dl=1'\n",
    "\n",
    "\n",
    "if not os.path.exists(check_file):\n",
    "    if not os.path.exists(nii_dir):\n",
    "        os.makedirs(nii_dir)\n",
    "    \n",
    "    if not os.path.exists(zipfile_fname):\n",
    "        with open(zipfile_fname, 'wb') as f:\n",
    "            data = requests.get(url).content\n",
    "            f.write(data)\n",
    "\n",
    "        shutil.unpack_archive(zipfile_fname, nii_dir)\n",
    "        os.remove(zipfile_fname)\n",
    "\n",
    "        with open(check_file, 'w+') as f:\n",
    "            f.write(str(dt.now()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_files = lsdir(os.path.join(nii_dir, 'Pieman2', '*', 'func', '*.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {os.path.split(f)[-1][:-len('.nii.gz')]: nlt.data.Brain_Data(data=f) for f in nii_files}\n",
    "\n",
    "with open(os.path.join(datadir, 'pieman2.pkl'), 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subj2cond(x):\n",
    "#     if 'intact' in x:\n",
    "#         return 'intact'\n",
    "#     elif 'paragraph' in x:\n",
    "#         return 'paragraph'\n",
    "#     elif 'word' in x:\n",
    "#         return 'word'\n",
    "#     elif 'rest' in x:\n",
    "#         return 'rest'\n",
    "#     else:\n",
    "#         raise Exception('Unknown condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = {}\n",
    "# for k, v in data.items():\n",
    "#     if subj2cond(k) in x:\n",
    "#         x[subj2cond(k)].append(v)\n",
    "#     else:\n",
    "#         x[subj2cond(k)] = [v]\n",
    "\n",
    "# with open(os.path.join(datadir, 'pieman2_organized.pkl'), 'wb') as f:\n",
    "#     pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "\n",
    "def load_data(fname):\n",
    "    htfa = loadmat(fname, simplify_cells=True)['posterior']\n",
    "    weights = [pd.DataFrame(htfa['subjects'][i]['image_weights']['mean']) for i in range(len(htfa['subjects']))]\n",
    "    data = {}    \n",
    "    for c in conditions:\n",
    "        data[c] = [w for w, n in zip(weights, htfa['subjects_names']) if c in n]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data(fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (computing and saving as needed) the reduced versions of the data using $k \\in \\{3, 4, 5, ..., 700\\}$ components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_pca(data, n_components=None):\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    x = dw.stack(data)\n",
    "    y = pca.fit_transform(x)\n",
    "\n",
    "    return dw.unstack(pd.DataFrame(index=x.index, data=y))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 698/698 [00:08<00:00, 78.53it/s] \n",
      "100%|██████████| 698/698 [00:03<00:00, 215.67it/s]\n",
      "100%|██████████| 698/698 [23:10<00:00,  1.99s/it] \n",
      "100%|██████████| 698/698 [33:27<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "scratch_dir = os.path.join(basedir, 'data', 'scratch')\n",
    "if not os.path.exists(scratch_dir):\n",
    "    os.makedirs(scratch_dir)\n",
    "\n",
    "reduced_data = {}\n",
    "max_components = data['intact'][0].shape[1]\n",
    "\n",
    "for c in conditions:\n",
    "    reduced_data[c] = {}\n",
    "    for n in tqdm(range(3, max_components + 1)):\n",
    "        fname = os.path.join(scratch_dir, f'pca_{c}_{n}.pkl')        \n",
    "\n",
    "        if not os.path.exists(fname):\n",
    "            reduced_data[c][n] = group_pca(data[c], n_components=n)\n",
    "\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(reduced_data[c][n], f)\n",
    "\n",
    "        with open(fname, 'rb') as f:\n",
    "            reduced_data[c][n] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(train, test):\n",
    "    train = np.mean(np.stack(train, axis=2), axis=2)\n",
    "    test = np.mean(np.stack(test, axis=2), axis=2)\n",
    "    dists = cdist(train, test, metric='correlation')\n",
    "    \n",
    "    labels = np.argmin(dists, axis=1)\n",
    "    return np.mean([i == d for i, d in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, n_folds=100):\n",
    "    results = pd.DataFrame(columns=['Fold', 'Number of components', 'Decoding accuracy'])\n",
    "\n",
    "    n = len(data[3]) // 2\n",
    "    for i in tqdm(range(n_folds)):\n",
    "        order = np.random.permutation(len(data[3]))\n",
    "\n",
    "        for c in range(3, max_components + 1):\n",
    "            x = pd.DataFrame(columns=['Fold', 'Number of components', 'Decoding accuracy'])\n",
    "            x.loc[0, 'Fold'] = i\n",
    "            x.loc[0, 'Number of components'] = c\n",
    "\n",
    "            train = [data[c][o] for o in order[:n]]\n",
    "            test = [data[c][o] for o in order[n:]]\n",
    "            x.loc[0, 'Decoding accuracy'] = (accuracy(train, test) + accuracy(test, train)) / 2\n",
    "\n",
    "            results = pd.concat([results, x], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [9:44:13<00:00, 350.54s/it]  \n",
      "  8%|▊         | 8/100 [1:20:41<15:37:13, 611.23s/it]"
     ]
    }
   ],
   "source": [
    "decoding_results = {}\n",
    "for c in conditions:\n",
    "    decoding_results[c] = cross_validation(reduced_data[c])\n",
    "    sns.lineplot(decoding_results[c], x='Number of components', y='Decoding accuracy', label=c.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2374a5d97dbff2383fb72c506230f21570e3388024304ec3ac10b13478d174bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

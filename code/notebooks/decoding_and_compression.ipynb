{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: davos in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (from davos) (65.6.3)\n",
      "Requirement already satisfied: packaging in /Users/jmanning/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages (from davos) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install davos\n",
    "import davos\n",
    "\n",
    "davos.config.suppress_stdout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smuggle datawrangler as dw        # pip: pydata-wrangler==0.2.2\n",
    "\n",
    "smuggle numpy as np               # pip: numpy==1.24.2\n",
    "smuggle matplotlib.pyplot as plt  # pip: matplotlib==3.7.0\n",
    "smuggle pandas as pd              # pip: pandas==1.5.3\n",
    "smuggle seaborn as sns            # pip: seaborn==0.12.2\n",
    "\n",
    "from sklearn.decomposition smuggle IncrementalPCA as PCA  # pip: scikit-learn==1.2.1\n",
    "from scipy.spatial.distance smuggle cdist                 # pip: scipy==1.10.1\n",
    "from scipy.io smuggle loadmat\n",
    "from tqdm smuggle tqdm            # pip: tqdm==4.64.1\n",
    "\n",
    "smuggle requests                  # pip: requests==2.28.2\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.path.split(os.path.split(os.getcwd())[0])[0]\n",
    "datadir = os.path.join(basedir, 'data')\n",
    "\n",
    "fname = os.path.join(datadir, 'pieman_posterior_K700.mat')\n",
    "url = 'https://www.dropbox.com/s/0g5nx37p64eubif/pieman_posterior_K700.mat?dl=1'\n",
    "\n",
    "if not os.path.exists(fname):\n",
    "    with open(fname, 'wb') as f:\n",
    "        data = requests.get(url).content\n",
    "        f.write(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "\n",
    "def load_data(fname):\n",
    "    htfa = loadmat(fname, simplify_cells=True)['posterior']\n",
    "    weights = [pd.DataFrame(htfa['subjects'][i]['image_weights']['mean']) for i in range(len(htfa['subjects']))]\n",
    "    data = {}    \n",
    "    for c in conditions:\n",
    "        data[c] = [w for w, n in zip(weights, htfa['subjects_names']) if c in n]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = load_data(fname)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load (computing and saving as needed) the reduced versions of the data using $k \\in \\{3, 4, 5, ..., 700\\}$ components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_pca(data, n_components=None):\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    x = dw.stack(data)\n",
    "    y = pca.fit_transform(x)\n",
    "\n",
    "    return dw.unstack(pd.DataFrame(index=x.index, data=y))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 248/248 [00:00<00:00, 335.24it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 774.60it/s] \n",
      "100%|██████████| 248/248 [00:00<00:00, 325.22it/s]\n",
      "100%|██████████| 248/248 [00:00<00:00, 392.98it/s]\n"
     ]
    }
   ],
   "source": [
    "scratch_dir = os.path.join(basedir, 'data', 'scratch')\n",
    "if not os.path.exists(scratch_dir):\n",
    "    os.makedirs(scratch_dir)\n",
    "\n",
    "reduced_data = {}\n",
    "max_components = data['intact'][0].shape[1]\n",
    "\n",
    "for c in conditions:\n",
    "    reduced_data[c] = {}\n",
    "    for n in tqdm(range(3, max_components + 1)):\n",
    "        fname = os.path.join(scratch_dir, f'pca_{c}_{n}.pkl')        \n",
    "\n",
    "        if not os.path.exists(fname):\n",
    "            reduced_data[c][n] = group_pca(data[c], n_components=n)\n",
    "\n",
    "            with open(fname, 'wb') as f:\n",
    "                pickle.dump(reduced_data[c][n], f)\n",
    "\n",
    "        with open(fname, 'rb') as f:\n",
    "            reduced_data[c][n] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(train, test):\n",
    "    train = np.mean(np.stack(train, axis=2), axis=2)\n",
    "    test = np.mean(np.stack(test, axis=2), axis=2)\n",
    "    dists = cdist(train, test, metric='correlation')\n",
    "    \n",
    "    labels = np.argmin(dists, axis=1)\n",
    "    return np.mean([i == d for i, d in enumerate(labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, n_folds=100):\n",
    "    results = pd.DataFrame(columns=['Fold', 'Number of components', 'Decoding accuracy'])\n",
    "\n",
    "    n = len(data[3]) // 2\n",
    "    for i in tqdm(range(n_folds)):\n",
    "        order = np.random.permutation(len(data[3]))\n",
    "\n",
    "        for c in range(3, max_components + 1):\n",
    "            x = pd.DataFrame(columns=['Fold', 'Number of components', 'Decoding accuracy'])\n",
    "            x.loc[0, 'Fold'] = i\n",
    "            x.loc[0, 'Number of components'] = c\n",
    "\n",
    "            train = [data[c][o] for o in order[:n]]\n",
    "            test = [data[c][o] for o in order[n:]]\n",
    "            x.loc[0, 'Decoding accuracy'] = (accuracy(train, test) + accuracy(test, train)) / 2\n",
    "\n",
    "            results = pd.concat([results, x], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [03:46<02:30,  3.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m decoding_results \u001b[39m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m conditions:\n\u001b[0;32m----> 3\u001b[0m     decoding_results[c] \u001b[39m=\u001b[39m cross_validation(reduced_data[c])\n\u001b[1;32m      4\u001b[0m     sns\u001b[39m.\u001b[39mlineplot(decoding_results[c], x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of components\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDecoding accuracy\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mcapitalize())\n",
      "Cell \u001b[0;32mIn[45], line 15\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(data, n_folds)\u001b[0m\n\u001b[1;32m     13\u001b[0m         train \u001b[39m=\u001b[39m [data[c][o] \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m order[:n]]\n\u001b[1;32m     14\u001b[0m         test \u001b[39m=\u001b[39m [data[c][o] \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m order[n:]]\n\u001b[0;32m---> 15\u001b[0m         x\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDecoding accuracy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (accuracy(train, test) \u001b[39m+\u001b[39m accuracy(test, train)) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     17\u001b[0m         results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([results, x], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m      2\u001b[0m train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mstack(train, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mstack(test, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m dists \u001b[39m=\u001b[39m cdist(train, test, metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcorrelation\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(dists, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean([i \u001b[39m==\u001b[39m d \u001b[39mfor\u001b[39;00m i, d \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels)])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages/scipy/spatial/distance.py:2939\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m \u001b[39mif\u001b[39;00m metric_info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2938\u001b[0m     cdist_fn \u001b[39m=\u001b[39m metric_info\u001b[39m.\u001b[39mcdist_func\n\u001b[0;32m-> 2939\u001b[0m     \u001b[39mreturn\u001b[39;00m cdist_fn(XA, XB, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2940\u001b[0m \u001b[39melif\u001b[39;00m mstr\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mtest_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   2941\u001b[0m     metric_info \u001b[39m=\u001b[39m _TEST_METRICS\u001b[39m.\u001b[39mget(mstr, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages/scipy/spatial/distance.py:1667\u001b[0m, in \u001b[0;36mCDistMetricWrapper.__call__\u001b[0;34m(self, XA, XB, out, **kwargs)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[39m# get cdist wrapper\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m cdist_fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_distance_wrap, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcdist_\u001b[39m\u001b[39m{\u001b[39;00mmetric_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mtyp\u001b[39m}\u001b[39;00m\u001b[39m_wrap\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1667\u001b[0m cdist_fn(XA, XB, dm, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1668\u001b[0m \u001b[39mreturn\u001b[39;00m dm\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pca-paper/lib/python3.9/site-packages/scipy/spatial/distance.py:138\u001b[0m, in \u001b[0;36m_correlation_cdist_wrap\u001b[0;34m(XA, XB, dm, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m XA \u001b[39m=\u001b[39m XA \u001b[39m-\u001b[39m XA\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    137\u001b[0m XB \u001b[39m=\u001b[39m XB \u001b[39m-\u001b[39m XB\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 138\u001b[0m _distance_wrap\u001b[39m.\u001b[39;49mcdist_cosine_double_wrap(XA, XB, dm, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "decoding_results = {}\n",
    "for c in conditions:\n",
    "    decoding_results[c] = cross_validation(reduced_data[c])\n",
    "    sns.lineplot(decoding_results[c], x='Number of components', y='Decoding accuracy', label=c.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pca-paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2374a5d97dbff2383fb72c506230f21570e3388024304ec3ac10b13478d174bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

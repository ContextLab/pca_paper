\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{MackEtal20}
\citation{ZhouEtal19}
\citation{EckaYoun36}
\citation{SimoEtal16}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Illustration of compression.} Visual analogy for neural compression. Here are 2 images of pies, one more complex than the other. \textbf  {a.} It takes fewer components to reach the same percent variance explained in the less complex pie, which corresponds to higher compression. \textbf  {b.} However, with very few components, similar variance is explained in both pies. \textbf  {c.} Plots the cumulative explained variance for more and more components.}}{2}{figure.1}\protected@file@percent }
\newlabel{fig4:pie_example}{{1}{2}{\textbf {Illustration of compression.} Visual analogy for neural compression. Here are 2 images of pies, one more complex than the other. \textbf {a.} It takes fewer components to reach the same percent variance explained in the less complex pie, which corresponds to higher compression. \textbf {b.} However, with very few components, similar variance is explained in both pies. \textbf {c.} Plots the cumulative explained variance for more and more components}{figure.1}{}}
\citation{SimoEtal16}
\citation{MannEtal18}
\citation{SimoEtal16}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Decoding accuracy.} \textbf  {a. Decoding accuracy by number of components.} Ribbons of each color display cross-validated decoding performance for each condition (intact, paragraph, word, and rest). Decoders were trained using increasingly more principle components and displayed relative to chance (red line). \textbf  {b. Fixed decoding accuracy by number of components.} We zoom in on the plot shown in \textbf  {a.} and add a line denoting fixed decoding accuracy (.05). We plot where the intact, paragraph, and word conditions intersect. \textbf  {c. Explanation of inflection metric.} First the we fit a sigmoid function to the decoding accuracy by number of components. Second, we found where the second derivative is both positive and less than .0001. Last, we then plot that inflection point as a single metric to capture the slope and asymptote of the curve.}}{4}{figure.2}\protected@file@percent }
\newlabel{fig:decode_interpret}{{2}{4}{\textbf {Decoding accuracy.} \textbf {a. Decoding accuracy by number of components.} Ribbons of each color display cross-validated decoding performance for each condition (intact, paragraph, word, and rest). Decoders were trained using increasingly more principle components and displayed relative to chance (red line). \textbf {b. Fixed decoding accuracy by number of components.} We zoom in on the plot shown in \textbf {a.} and add a line denoting fixed decoding accuracy (.05). We plot where the intact, paragraph, and word conditions intersect. \textbf {c. Explanation of inflection metric.} First the we fit a sigmoid function to the decoding accuracy by number of components. Second, we found where the second derivative is both positive and less than .0001. Last, we then plot that inflection point as a single metric to capture the slope and asymptote of the curve}{figure.2}{}}
\citation{YeoEtal11}
\citation{YeoEtal11}
\citation{YeoEtal11}
\citation{YeoEtal11}
\citation{Deme19}
\citation{Turk13}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Inflection points by network.} \textbf  {a.} Inflection point was calculated as explained in Fig.\nobreakspace  {}\ref  {fig4:decode_interpret}, b. Analyses were limited by the brain networks (using the \cite  {YeoEtal11} network parcellation) and arranged in increasing order relative to the intact condition. \textbf  {b. and c.} For the total time in the intact condition, we are plotting the relative inflection points (\textbf  {b.}) and corresponding number of components (\textbf  {c.}) by network. \textbf  {d.} The network parcellation defined by \cite  {YeoEtal11} is displayed on the inflated brain maps. The colors and network labels serve as a legend for \textbf  {a.} and \textbf  {d.}}}{6}{figure.3}\protected@file@percent }
\newlabel{fig:decode_pcs_network}{{3}{6}{\textbf {Inflection points by network.} \textbf {a.} Inflection point was calculated as explained in Fig.~\ref {fig4:decode_interpret}, b. Analyses were limited by the brain networks (using the \cite {YeoEtal11} network parcellation) and arranged in increasing order relative to the intact condition. \textbf {b. and c.} For the total time in the intact condition, we are plotting the relative inflection points (\textbf {b.}) and corresponding number of components (\textbf {c.}) by network. \textbf {d.} The network parcellation defined by \cite {YeoEtal11} is displayed on the inflated brain maps. The colors and network labels serve as a legend for \textbf {a.} and \textbf {d.}}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Inflection points by thirds.} \textbf  {a.} Decoding accuracy by number of components not broken into thirds (Fig.\nobreakspace  {}\ref  {fig4:decode_interpret} a.). \textbf  {b. and c.} Quantifying changes in decoding accuracy across time. \textbf  {b.} Slope of decoding accuracy was calculated by fitting a regression line for each component/condition for each third. \textbf  {c.} We also repeated the analysis (Fig.\nobreakspace  {}\ref  {fig4:decode_interpret}, b.) to obtain the inflection point for each condition and for each third. \textbf  {d.} Decoding accuracy by number of components for each third of the scan time. We repeated the same analysis in Fig.\nobreakspace  {}\ref  {fig4:decode_interpret} a. but breaking the scan time for each condition into 3 intervals. }}{7}{figure.4}\protected@file@percent }
\newlabel{fig:decode_pcs_thirds}{{4}{7}{\textbf {Inflection points by thirds.} \textbf {a.} Decoding accuracy by number of components not broken into thirds (Fig.~\ref {fig4:decode_interpret} a.). \textbf {b. and c.} Quantifying changes in decoding accuracy across time. \textbf {b.} Slope of decoding accuracy was calculated by fitting a regression line for each component/condition for each third. \textbf {c.} We also repeated the analysis (Fig.~\ref {fig4:decode_interpret}, b.) to obtain the inflection point for each condition and for each third. \textbf {d.} Decoding accuracy by number of components for each third of the scan time. We repeated the same analysis in Fig.~\ref {fig4:decode_interpret} a. but breaking the scan time for each condition into 3 intervals}{figure.4}{}}
\citation{SimoEtal16}
\bibstyle{apacite}
\bibdata{cdl.bib}
\gdef \@abspage@last{9}
